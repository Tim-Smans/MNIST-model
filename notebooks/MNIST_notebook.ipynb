{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe9a77db-6d1f-48d3-9100-e778585bdda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished importing libraries\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Finished importing libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae9ec91-4daf-4c12-93c8-a4df06294d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading data\n"
     ]
    }
   ],
   "source": [
    "#Loading data \n",
    "\n",
    "#Compose is used to combine multiple transformations\n",
    "# ToTensor -> Converts PIL-image to pyTorch tensor (value between 0 and 1)\n",
    "# Normalize -> Normalizes the pixel values so they are between 0 and 1. This helps the model to run more smoothly\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Loads in the MNIST dataset and saves it in ./data\n",
    "# Train -> Because we want to use training data.\n",
    "# Download -> It will download the data if it isn't avaible yet.\n",
    "# Transform -> Apply's the transformations we declared above.\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True,\n",
    "    download=True, transform=transform\n",
    ")\n",
    "#Converts the dataset to a dataloader. This will deliver batches for training.\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "#Same thing for testing data.\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False,\n",
    "    download=True, transform=transform\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Selecteer een afbeelding uit de dataset (bijvoorbeeld de eerste afbeelding)\n",
    "image, label = testset[101]\n",
    "\n",
    "# Converteer de afbeelding terug naar een bruikbaar formaat\n",
    "# De afbeelding is genormaliseerd, dus we moeten deze denormaliseren\n",
    "image = image * 0.5 + 0.5  # Denormaliseer\n",
    "image = transforms.ToPILImage()(image)  # Converteer naar PIL-afbeelding\n",
    "\n",
    "# Sla de afbeelding op als een PNG-bestand\n",
    "image.save(\"mnist_image.png\")\n",
    "\n",
    "print(\"Finished loading data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f25e8e9-680e-4710-99dd-4a68b5d61aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished defining the model\n"
     ]
    }
   ],
   "source": [
    "#Defining a pyTorch model\n",
    "# We also initialise this model using the pyCharm nn.Module  \n",
    "\n",
    "# self.fc:\n",
    "# nn.Sequential -> Makes sure they everthing inside is run top to bottom\n",
    "# Flatten -> Transforms 2D image into a vector. A fully connected layer expects a 1D-array\n",
    "# Linear 1 -> This is a fully connected (dense) layer. The input has 784 Neurons (1 for every pixel). \n",
    "#           The output has 128 Neurons which means we get back 128 features. This will recognize important paterns.\n",
    "# ReLU   -> This is complex, Will look into it later.\n",
    "# Linear 2 -> This is the output layer. The input has 128 features and will return 10 neurons. One for every number 0-9\n",
    "\n",
    "# Forward -> Sends an image through all the steps from self.fc\n",
    " \n",
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "#Initialises the model. \n",
    "model = MNISTModel()\n",
    "\n",
    "print(\"Finished defining the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1bc1e3f-13b8-471f-9582-bd793d96a6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished defining loss function\n"
     ]
    }
   ],
   "source": [
    "#This defines the loss function that is used to measure how good/bad the model is operating.\n",
    "# It gives a high value when the model makes a bad prediction and a low value when it makes a good prediction.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Here we decide how the model learns\n",
    "# Adam -> Is a popular model optimiser, it changes the weights of the network to minimize loss.\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "print(\"Finished defining loss function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4084f40-1dd2-491f-a2ea-71c6e1935c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 1/5 Loss: 0.3467\n",
      "Epoch 2/5 Loss: 0.1762\n",
      "Epoch 3/5 Loss: 0.1307\n",
      "Epoch 4/5 Loss: 0.1081\n",
      "Epoch 5/5 Loss: 0.0959\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "#Epoch = A loop of the entire training data.\n",
    "#Loss = The loss of an epoch is how bad the model is operating. The goal is to get this as low as possible\n",
    "#       but not 0, because that would be overfitting the model.\n",
    "\n",
    "#Inside the trainloader (which will run the training data in batches):\n",
    "# optimizer -> Responsible for updating the mode weights. .zero_grod() makes sure it is reset to 0 at the start of every batch\n",
    "# outputs = model(images) -> This feeds the images into the neural network model. \n",
    "# loss -> This compares the model predictions (the outputs) to the labels, a higher loss means the model is performing poorly\n",
    "# loss.backward -> This is backpropagation, here we calculate how much weight each weight in the model is contributed to the error.\n",
    "# optimizer.step -> This updates the weights of the model based on what is calculated in loss.backward.\n",
    "\n",
    "print(\"Starting training\")\n",
    "\n",
    "epochs = 5 \n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()         \n",
    "        outputs = model(images)      \n",
    "        loss = criterion(outputs, labels) \n",
    "        loss.backward()                   \n",
    "        optimizer.step()               \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} Loss: {running_loss/len(trainloader):.4f}\")\n",
    "\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e1253c-9261-4b96-a9fc-87fb0ea4d177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.01%\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "#Here we are evaluating how good our model is performing, and just how accurate it is when testing.\n",
    "#torch.no_grad -> Disables gradients, to speed up calculations.\n",
    "#predicted -> Stores the index of the highest value, which is also the predicted digit.\n",
    "#correct -> Counts how many of the predictions where correct and adds it to correct.\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad(): \n",
    "    for images, labels in testloader:\n",
    "        outputs = model(images) \n",
    "        _, predicted = torch.max(outputs, 1) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8328606f-9983-47be-ba95-9c50f70a91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving my trained model\n",
    "\n",
    "model_path = \"mnist_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c442f5fc-7334-4833-a615-d2b93b7fb970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicts: 7, Correct answer: 7\n"
     ]
    }
   ],
   "source": [
    "#Using the model to predict a random number\n",
    "#We pick an image out of our array of testing data and let our trained model predict the number that is on it.\n",
    "# plt.imshow -> Plots the image\n",
    "# .show -> Shows the image. \n",
    "# .unqsueeze -> Because our model expects a batch of images we have to make our single image into a batch. \n",
    "#               unsqueezing the image creates a batch of one image.\n",
    "# model.eval -> Puts the model into evaluation mode.\n",
    "\n",
    "sample_image, sample_label = testset[0]  \n",
    "plt.imshow(sample_image.squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "sample_image = sample_image.unsqueeze(0) \n",
    "model.eval() \n",
    "prediction = model(sample_image)\n",
    "predicted_label = torch.argmax(prediction).item()\n",
    "print(f\"Model predicts: {predicted_label}, Correct answer: {sample_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb623329-d494-41cf-8d0c-551cc55d8302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
